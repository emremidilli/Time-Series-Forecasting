{"trial_id": "0001", "hyperparameters": {"space": [{"class_name": "Int", "config": {"name": "nr_of_encoder_blocks", "default": null, "conditions": [], "min_value": 2, "max_value": 6, "step": 1, "sampling": "linear"}}, {"class_name": "Int", "config": {"name": "nr_of_heads", "default": null, "conditions": [], "min_value": 2, "max_value": 16, "step": 2, "sampling": "linear"}}, {"class_name": "Int", "config": {"name": "nr_of_ffn_units_of_encoder", "default": null, "conditions": [], "min_value": 16, "max_value": 128, "step": 16, "sampling": "linear"}}, {"class_name": "Int", "config": {"name": "embedding_dims", "default": null, "conditions": [], "min_value": 4, "max_value": 64, "step": 6, "sampling": "linear"}}, {"class_name": "Float", "config": {"name": "dropout_rate", "default": 0.01, "conditions": [], "min_value": 0.01, "max_value": 0.9, "step": 0.1, "sampling": "linear"}}], "values": {"nr_of_encoder_blocks": 2, "nr_of_heads": 10, "nr_of_ffn_units_of_encoder": 112, "embedding_dims": 52, "dropout_rate": 0.7100000000000001, "tuner/epochs": 2, "tuner/initial_epoch": 0, "tuner/bracket": 4, "tuner/round": 0}}, "metrics": {"metrics": {}}, "score": null, "best_step": 0, "status": "FAILED", "message": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/base_tuner.py\", line 270, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/base_tuner.py\", line 235, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/keras_tuner/tuners/hyperband.py\", line 425, in run_trial\n    return super().run_trial(trial, *fit_args, **fit_kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/tuner.py\", line 287, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/tuner.py\", line 214, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n  File \"/workspace/hyperparameter_tuning/pre_train.py\", line 104, in fit\n    return model.fit(\n  File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:\n\nDetected at node 'representation/transformer_encoder_5/multi_head_attention_5/key/einsum_2/Einsum' defined at (most recent call last):\n    File \"/workspace/hyperparameter_tuning/pre_train.py\", line 207, in <module>\n      oTunerArchitecture.search(\n    File \"/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/base_tuner.py\", line 230, in search\n      self._try_run_and_update_trial(trial, *fit_args, **fit_kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/base_tuner.py\", line 270, in _try_run_and_update_trial\n      self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/base_tuner.py\", line 235, in _run_and_update_trial\n      results = self.run_trial(trial, *fit_args, **fit_kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras_tuner/tuners/hyperband.py\", line 425, in run_trial\n      return super().run_trial(trial, *fit_args, **fit_kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/tuner.py\", line 287, in run_trial\n      obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/tuner.py\", line 214, in _build_and_fit_model\n      results = self.hypermodel.fit(hp, model, *args, **kwargs)\n    File \"/workspace/hyperparameter_tuning/pre_train.py\", line 104, in fit\n      return model.fit(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/workspace/hyperparameter_tuning/../models/pre_training.py\", line 210, in train_step\n      (dist_false, tre_false, sea_false))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/workspace/hyperparameter_tuning/../layers/general_pre_training/representation.py\", line 111, in call\n      for encoder in self.encoders_cont_temp:\n    File \"/workspace/hyperparameter_tuning/../layers/general_pre_training/representation.py\", line 112, in call\n      x_cont_temp = encoder(x_cont_temp)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/workspace/hyperparameter_tuning/../layers/general_pre_training/transformer_encoder.py\", line 39, in call\n      x = self.oMha_1(x, x)  # self-attention\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/layers/attention/multi_head_attention.py\", line 593, in call\n      key = self._key_dense(key)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/layers/core/einsum_dense.py\", line 207, in call\n      ret = tf.einsum(self.equation, inputs, self.kernel)\nNode: 'representation/transformer_encoder_5/multi_head_attention_5/key/einsum_2/Einsum'\nOOM when allocating tensor with shape[11264,520] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node representation/transformer_encoder_5/multi_head_attention_5/key/einsum_2/Einsum}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_199339]\n"}