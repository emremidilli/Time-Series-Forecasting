{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29dc4135-d866-436c-baaa-d0ea79cabfff",
   "metadata": {},
   "source": [
    "Inputs:\n",
    "\n",
    "    * Tokenized data.\n",
    "    \n",
    "Analysis:\n",
    "\n",
    "    * Mask some of the inputs tokens that are not special ones. Use MASK_RATE. Signs of deltas for special tokens are set as zero.\n",
    "    \n",
    "Outputs:\n",
    "\n",
    "    * Signs of deltas of the tokenized data. Signs are represented in one-hot format. Output shape is (nr_of_samples, nr_of_positions, nr_of_quantiles x 3)\n",
    "    * nr_of_quantiles are multiplied by 3 to represent in one-hot format.\n",
    "    * 3 means {positive, negative and zero}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fd26cd9-6142-4ba0-a83d-657edf3b3275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import constants as c\n",
    "\n",
    "import os\n",
    "\n",
    "import shutil\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "542e1b18-b4bf-40c4-bef3-d4a591211a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6ef38a7-8eb1-48c7-a572-af4267b9cd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGN_OF_PATCH_PREDICTION_DATA_FOLDER = c.SIGN_OF_PATCH_PREDICTION_DATA_FOLDER\n",
    "TOKENIZIED_DATA_FOLDER = c.TOKENIZIED_DATA_FOLDER\n",
    "CONSOLIDATED_CHANNEL_DATA_FOLDER = c.CONSOLIDATED_CHANNEL_DATA_FOLDER\n",
    "\n",
    "MASK_RATE = c.MASK_RATE\n",
    "\n",
    "MSK_SCALAR = c.MSK_SCALAR\n",
    "\n",
    "FORECAST_HORIZON = c.FORECAST_HORIZON\n",
    "LOOKBACK_COEFFICIENT = c.LOOKBACK_COEFFICIENT\n",
    "PATCH_SIZE = c.PATCH_SIZE\n",
    "\n",
    "iNrOfLookbackPatches = int((FORECAST_HORIZON*LOOKBACK_COEFFICIENT)/PATCH_SIZE)\n",
    "iNrOfForecastPatches = int(FORECAST_HORIZON/PATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a2c254-7553-49f0-93b8-3282593ec2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(SIGN_OF_PATCH_PREDICTION_DATA_FOLDER) == True:\n",
    "    shutil.rmtree(SIGN_OF_PATCH_PREDICTION_DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef3fb6f5-3501-4269-90ef-829f059334ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "aDistribution = np.load(f'{TOKENIZIED_DATA_FOLDER}\\\\distribution.npy')\n",
    "aDynamicDigits = np.load(f'{TOKENIZIED_DATA_FOLDER}\\\\dynamic_digits.npy')\n",
    "aTrend = np.load(f'{TOKENIZIED_DATA_FOLDER}\\\\trend.npy')\n",
    "aSeasonality = np.load(f'{TOKENIZIED_DATA_FOLDER}\\\\seasonality.npy')\n",
    "\n",
    "aDeltas = np.load(f'{CONSOLIDATED_CHANNEL_DATA_FOLDER}\\\\deltas.npy')\n",
    "\n",
    "aSignsOfDeltas = np.sign(aDeltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42c0265e-8c0c-4e39-9ce7-271a3be0cd7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def aGetSppDatasets(aTrueInput):\n",
    "    aMaskedInput = aTrueInput.copy()\n",
    "\n",
    "    iNrOfTimePatches = iNrOfForecastPatches + iNrOfLookbackPatches\n",
    "    iNrOfFeaturesPerChannel = iNrOfTimePatches + 4 \n",
    "    iNrOfChannels = int(aTrueInput.shape[1]/iNrOfFeaturesPerChannel)\n",
    "    iNrOfSamples = aTrueInput.shape[0]\n",
    "\n",
    "    aLookbackPatchesToMask = np.random.rand(iNrOfSamples, iNrOfLookbackPatches )\n",
    "    aLookbackPatchesToMask = aLookbackPatchesToMask.argsort()[:, :int((MASK_RATE) * (iNrOfLookbackPatches))]\n",
    "    aLookbackPatchesToMask.sort(axis = 1)\n",
    "\n",
    "\n",
    "    aForecastPatchesToMask = np.random.rand(iNrOfSamples, iNrOfForecastPatches )\n",
    "    aForecastPatchesToMask = aForecastPatchesToMask.argsort()[:, :int((MASK_RATE) * (iNrOfForecastPatches - 1))] #latest forecast doesn't have delta. \n",
    "    aForecastPatchesToMask.sort(axis = 1)\n",
    "\n",
    "\n",
    "    aOutput = np.zeros((iNrOfSamples, aTrueInput.shape[1],aSignsOfDeltas.shape[2]))\n",
    "\n",
    "    for i in range(iNrOfChannels):\n",
    "        aDeltasOfChannel = aSignsOfDeltas[:,:,:, i]\n",
    "\n",
    "        # cls: beginning of each channel.\n",
    "        iFirstTokenIndex = i * iNrOfFeaturesPerChannel \n",
    "        iLastTokenIndex = iFirstTokenIndex + iNrOfFeaturesPerChannel - 1 \n",
    "\n",
    "        # lookback window: after cls \n",
    "        iLookbackStartIndex = iFirstTokenIndex+1\n",
    "        iLookbackEndIndex = iLookbackStartIndex + iNrOfLookbackPatches - 1\n",
    "\n",
    "        # forecast window: \n",
    "        iForecastStartIndex = iLookbackEndIndex+2 # (there is [SEP] between end of lookback and start of forecast)\n",
    "        iForecastEndIndex = iForecastStartIndex + iNrOfForecastPatches - 1\n",
    "\n",
    "\n",
    "        for j in range(iNrOfLookbackPatches):\n",
    "            ix = (aLookbackPatchesToMask == j).any(axis = 1)\n",
    "\n",
    "            aMaskedInput[ix, iLookbackStartIndex + j, :] = MSK_SCALAR\n",
    "\n",
    "            aOutput[ix, iLookbackStartIndex + j, :] = aSignsOfDeltas[ix, j ,:, i]\n",
    "\n",
    "\n",
    "            \n",
    "        for j in range(iNrOfForecastPatches - 1): #1 due to latest forecast patch can not be masked.\n",
    "            ix = (aForecastPatchesToMask == j).any(axis = 1)\n",
    "\n",
    "            aMaskedInput[ix, iForecastStartIndex + j, :] = MSK_SCALAR\n",
    "\n",
    "            aOutput[ix, iForecastStartIndex + j, :] = aSignsOfDeltas[ix, iNrOfLookbackPatches + j ,:, i]\n",
    "\n",
    "\n",
    "\n",
    "    X = aMaskedInput.copy()\n",
    "    Y = aOutput.copy()\n",
    "    \n",
    "    \n",
    "    # do not include negative values. make sure that all the values are between 0 and 1.\n",
    "    # -1 -> negative sign, \n",
    "    # 0 -> zero (neigther negative nor positive)  \n",
    "    # 1 -> positive sign\n",
    "    oOneHotEncoder = OneHotEncoder( categories = [[-1, 0, 1]] ,sparse=False ,handle_unknown='ignore')    \n",
    "    aToReturn = np.zeros((Y.shape[0], Y.shape[1], Y.shape[2], 3)) # 3: positive, negative, zero\n",
    "    for i in range(Y.shape[1]):\n",
    "        for j in range(Y.shape[2]):\n",
    "            arr2 = Y[:, i, [j]]\n",
    "            aToReturn[:, i, j, : ] = oOneHotEncoder.fit_transform(arr2)\n",
    "    \n",
    "    Y = aToReturn.copy()\n",
    "    \n",
    "    Y = np.reshape(Y, (Y.shape[0], Y.shape[1], -1))\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "\n",
    "\n",
    "X_dist, Y_dist = aGetSppDatasets(aDistribution)\n",
    "X_tic, Y_tic = aGetSppDatasets(aDynamicDigits)\n",
    "X_tre, Y_tre = aGetSppDatasets(aTrend)\n",
    "X_sea, Y_sea = aGetSppDatasets(aSeasonality)\n",
    "\n",
    "\n",
    "os.makedirs(SIGN_OF_PATCH_PREDICTION_DATA_FOLDER)\n",
    "np.save(f'{SIGN_OF_PATCH_PREDICTION_DATA_FOLDER}\\\\X_dist.npy', X_dist)\n",
    "np.save(f'{SIGN_OF_PATCH_PREDICTION_DATA_FOLDER}\\\\Y_dist.npy', Y_dist)\n",
    "\n",
    "np.save(f'{SIGN_OF_PATCH_PREDICTION_DATA_FOLDER}\\\\X_tic.npy', X_tic)\n",
    "np.save(f'{SIGN_OF_PATCH_PREDICTION_DATA_FOLDER}\\\\Y_tic.npy', Y_tic)\n",
    "\n",
    "np.save(f'{SIGN_OF_PATCH_PREDICTION_DATA_FOLDER}\\\\X_tre.npy', X_tre)\n",
    "np.save(f'{SIGN_OF_PATCH_PREDICTION_DATA_FOLDER}\\\\Y_tre.npy', Y_tre)\n",
    "\n",
    "np.save(f'{SIGN_OF_PATCH_PREDICTION_DATA_FOLDER}\\\\X_sea.npy', X_sea)\n",
    "np.save(f'{SIGN_OF_PATCH_PREDICTION_DATA_FOLDER}\\\\Y_sea.npy', Y_sea)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
